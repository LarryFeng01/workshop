## Response to Stevens Reading
#### In the readings for Tuesday and today (Stevens et al.) the authors use a technique to produce a high-resolution description of the distribution of human populations across the globe. What is the name of the technique and describe in general and basic terms how it works?


The article, Disaggregating Census Data for Population Mapping Using Random Forests with Remotely Sensed and Ancillary Data (Stevens et al.), they use a technique to produce the high resolution description of the distribution of human populations that the question refers to. The name of this technique is called "Random Forest Technique". First, the Random Forest models are an "ensemble, non-parametric modeling approach", in which the data produces a "forest" of their own classifications, also known as regression trees, and this improves the issue of bagging by using the best of a random selection. This technique also has an advantage which is having fewer "tuning parameters". So, how does this technique work? It first fits a series of models using the "tuneRF" function with every available covariate and log population density of each census unit as the response variable. Second, this step is a selection process for the resulting Random Forest, but it is also "very conservative" and uses the covariates. Then we use the resulting forest of trees and extract the "covariate importance scores". The next resulting Random Forest is used to predict on a scale of countries, with a very detailed map of log population densities. Lastly, the Random Forest model trees are distributed accordingly to one or more parallel processing environments and predictions are calculated for each pixel within the country. 

#### The random forest method used by the authors is a machine learning algorithm (ensemble method). In general terms, what is a machine learning algorithm? Within the context of this study what distinguishes a data science, machine learning method (such as random forest) from previous classical statistical approaches to describing and analyzing phenomenon and events?

A machine learning algorithm builds a mathematical model based on some sample data, so that it can make predictions without being programmed to perform that specific task. With classical statistical techniques, they are static in nature. They use one formula to send the sample data through, and they use the end result to predict factors. This approach, however, is not accurate for every data point in the sample and other factors. But with machine learning algorithms, it is possible to just let the computer use a wide variety of applications to accurately predict the results for each data point. When describing events and phenomenon, not every event is going to be the same as previous events, or even similar. With classical statistics, we can only pull from the most similar event that previously happened and use that to describe the event. But this approach is not the most accurate and might even be not accurate at all. 

#### In the reading, the authors use a number of geospatial covariates as predictors in their machine learning method. What were these geospatial covariates and approximately how big of a data set did they represent (in general terms)? What is the significance of big data in the estimation of machine learning methods for inferring the correlates and drivers of human population distributions?

The authors used a multitude of geospatial covariates, and I will continue by listing them all: cultivated terrestrial lands, trees, shrubs, herbaceous, other terrestrial vegetation, aquatic vegetation, urban area, bare areas, water bodies, no data/clouds, rural areas, industrial areas, merged urban, annual NPP, nighttime lights, mean temperature, mean precipitation, elevation, slope, distance to roads, distance to rivers, generic populated places, protected areas, canals, communities, district seats, cities, hamlets, villages, suburbs, towns, populated points, railways, generic health facilities, health clinics, dispensaries, hospitals, schools, settlement points, and built land cover. Factoring in the population, if we take an example country of 30 million people, then the total amount of data is multiplied by the number of covariates. In the paper, there are roughly 46 covariates. This means that the total data set size is increased from 30 million to 30 million times 46. With big data and machine learning, the more data there exists, the better for the machines. Since the machines don't have a formula to just apply to every data point, the machine has to figure out the relations of the data based solely on the numbers. Therefore, the more sample data, the more accurate and precise the results and predictors will be. 

#### The authorsâ€™ results present a remarkable improvement over previous geospatial descriptions at very high resolution, of the distribution of the human population. Within the context of human development in LMICs, what is the significance of having a highly accurate description of where each person is located across planet earth?

Lower middle-income countries generally don't take censuses. They cost far too many resources that the country can't afford to place in a census rather than in securing food for their citizens. It is, however, important for countries that are able to give aid to be able to locate the people that really need help instead of the wealthy in the LMIC. If a country is giving aid to another, they don't want to give the aid to the wrong hands. In order to counter-act this, a highly accurate description of where everyone resides is very useful. With this information, countries can locate which areas need aid and can even locate the transportation networks so that it can be delivered accordingly. 

#### Within the context of human development in LMICs, what is the relevance to your area of investigation in having a highly accurate description of where each household and person is located across planet earth?

In my area of investigation, I'm currently looking over the topic of poverty and food security in Ethiopia. If we were to look at a poverty assessment, it would be very important to have an accurate description of where every person is located. Since people with similar circumstances tend to reside in the same area, one can infer that the poor are located near the poverty area, and the wealthy reside where other wealthy people live. As well as other factors, this makes it possible to locate where people live and their living circumstances. 
